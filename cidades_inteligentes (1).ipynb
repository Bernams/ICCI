{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c-EuvCfYkwUx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from shapely.wkt import loads\n",
        "from folium.plugins import HeatMap\n",
        "from shapely.geometry import mapping\n",
        "from datetime import datetime, timedelta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def get_portugal_holidays(start_year, end_year):\n",
        "    portugal_holidays = []\n",
        "    for year in range(start_year, end_year + 1):\n",
        "        holidays = [\n",
        "            \"01/01\",  # New Year's Day\n",
        "            \"14/04\",  # Good Friday\n",
        "            \"16/04\",  # Easter Sunday\n",
        "            \"25/04\",  # Freedom Day\n",
        "            \"01/05\",  # Labor Day\n",
        "            \"10/06\",  # Portugal Day\n",
        "            \"15/06\",  # Corpus Christi\n",
        "            \"15/08\",  # Assumption Day\n",
        "            \"05/10\",  # Republic Day\n",
        "            \"01/11\",  # All Saints' Day\n",
        "            \"01/12\",  # Restoration of Independence\n",
        "            \"25/12\"   # Christmas Day\n",
        "        ]\n",
        "        holidays_with_year = [date + f\"/{year}\" for date in holidays]\n",
        "        portugal_holidays.extend([datetime.strptime(date, \"%d/%m/%Y\").date() for date in holidays_with_year])\n",
        "\n",
        "    return portugal_holidays\n",
        "\n",
        "start_year = 2021  \n",
        "end_year = 2023 \n",
        "\n",
        "portugal_holidays = get_portugal_holidays(start_year, end_year)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_time_of_day(hour):\n",
        "    if 6 < hour <= 12:\n",
        "        return 'Manhã'\n",
        "    elif 12 < hour <= 18:\n",
        "        return 'Tarde'\n",
        "    elif 18 < hour <= 24:\n",
        "        return 'Noite'\n",
        "    else:\n",
        "        return \"Madrugada\"\n",
        "\n",
        "def is_weekend(day):\n",
        "    return day.weekday() >= 5  \n",
        "\n",
        "def is_holiday(day):\n",
        "    return day in portugal_holidays\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "HEjIFjbwlOLG",
        "outputId": "a1f8f742-f74d-49f4-a77c-248b4777fcd1"
      },
      "outputs": [],
      "source": [
        "file_path = 'January2023.csv' \n",
        "file_path_e = 'wktComplete.csv'\n",
        "\n",
        "columns_to_keep_vodafone = ['Grid_ID','Datetime','C1', 'C3', 'C5', 'C6', 'E7', 'E8', 'E9']\n",
        "columns_to_keep_wkt = [\"grelha_id\", 'nome','latitude','longitude']\n",
        "\n",
        "df_dados_vodafone = pd.read_csv(file_path, encoding='latin1',usecols=columns_to_keep_vodafone)\n",
        "df_wkt = pd.read_csv(file_path_e,encoding='latin1',usecols=columns_to_keep_wkt)\n",
        "\n",
        "df_wkt = df_wkt.rename(columns={'grelha_id': 'Grid_ID'}) \n",
        "\n",
        "merged_df = pd.merge(df_dados_vodafone, df_wkt, on='Grid_ID')\n",
        "\n",
        "merged_df = merged_df.drop(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_df\n",
        "\n",
        "merged_df['datetime_column'] = pd.to_datetime(merged_df[\"Datetime\"])\n",
        "\n",
        "# Separate into date and hour columns\n",
        "merged_df['date'] = merged_df['datetime_column'].dt.date\n",
        "merged_df['Horas'] = merged_df['datetime_column'].dt.time\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "merged_df['Partes do dia'] = merged_df['datetime_column'].dt.hour.apply(get_time_of_day)\n",
        "merged_df['Fim-de-semana'] = merged_df['datetime_column'].dt.date.apply(is_weekend)\n",
        "merged_df['Feriado'] = merged_df['datetime_column'].dt.date.apply(is_holiday)\n",
        "\n",
        "\n",
        "df = merged_df.drop(columns=['datetime_column'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\berna\\AppData\\Local\\Temp\\ipykernel_19192\\2520258462.py:19: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df_no_duplicates[col] = df_no_duplicates[col].astype(str).str.replace('.', ',')\n",
            "C:\\Users\\berna\\AppData\\Local\\Temp\\ipykernel_19192\\2520258462.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_no_duplicates[col] = df_no_duplicates[col].astype(str).str.replace('.', ',')\n"
          ]
        }
      ],
      "source": [
        "patterns = ['IC19','Segunda Circular', '2ª Circular','Eixo Norte-Sul']\n",
        "numbers_list = [2548, 2549, 2608,2616,2617, 2670, 2731, 2792,2816,2214, 2852, 2911, 2972,3031,2973, 3032, 3091, 3092,3417, 3546, 3581, 3613, 3612, 3637, 3660, 3661, 3662, 3680, 3681, 3697, 2477, 2543, 2542, 2411, 1841, 1840, 1779, 1778, 1302, 1303, 1241, 1242, 1182, 1124, 1066, 1009, 953, 896, 839\n",
        "]\n",
        "\n",
        "combined_pattern = '|'.join(patterns)\n",
        "\n",
        "merged_df_truncated1 = df[df['Grid_ID'].isin(numbers_list)]\n",
        "\n",
        "\n",
        "merged_df_truncated2 = df[df.nome.str.contains(combined_pattern, regex=True)]\n",
        "\n",
        "concatenated_df = pd.concat([merged_df_truncated1, merged_df_truncated2], ignore_index=True)\n",
        "\n",
        "df_no_duplicates = concatenated_df.drop_duplicates()\n",
        "\n",
        "columns_to_format = ['C1', 'C3', 'C5', 'C6', 'E7', 'E8', 'E9']\n",
        "\n",
        "for col in columns_to_format:\n",
        "    df_no_duplicates[col] = df_no_duplicates[col].astype(str).str.replace('.', ',')\n",
        "\n",
        "\n",
        "df_no_duplicates.to_csv(\"January2023Clean.csv\", sep=';', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "362880"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_no_duplicates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del df_dados_vodafone, df_wkt, merged_df, patterns, combined_pattern"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
